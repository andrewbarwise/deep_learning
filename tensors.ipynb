{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 1280, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import imageio\n",
    "import torch\n",
    "\n",
    "img_arr = imageio.imread('data/bobby.jpg')\n",
    "\n",
    "img_arr.shape\n",
    "\n",
    "# img_array is a numpy array like object with three dimensions: two spatial dimensions, width and height and a third dimension corresponding to the\n",
    "# red, green and blue channels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the tensors 'permute' method with the old dimensions for each new dimension to get an appropiate layout\n",
    "\n",
    "# given an input tensor h * w * c we get a proper layout by having channel 2 first and then channels 0 and 1\n",
    "\n",
    "img = torch.from_numpy(img_arr)\n",
    "out = img.permute(2,0,1)\n",
    "\n",
    "# important to note that this operation does not make a copy of the tensor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to create a dataset of multiple images to use as an input for neural networks, store the images in a batch along the first dimension\n",
    "# to obtain a n*c*h*w tensor.\n",
    "\n",
    "# create a tensor of an appropiate size and fill it with images loaded from a directory\n",
    "\n",
    "batch_size = 3 \n",
    "batch = torch.zeros(batch_size, 3, 256, 256, dtype=torch.uint8)\n",
    "\n",
    "# this indicates our batch will consist of three RGB images 256 pixels in height and 256 pixels in length \n",
    "\n",
    "# each colour will be represented as an 8 bit integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[156, 152, 124,  ..., 150, 149, 158],\n",
      "         [174, 134, 165,  ..., 120, 136, 138],\n",
      "         [127, 156, 107,  ..., 131, 143, 164],\n",
      "         ...,\n",
      "         [116, 130, 129,  ..., 127, 118, 112],\n",
      "         [129, 130, 123,  ..., 115, 121, 114],\n",
      "         [129, 123, 118,  ..., 113, 121, 120]],\n",
      "\n",
      "        [[139, 135, 109,  ..., 135, 135, 147],\n",
      "         [160, 119, 149,  ..., 105, 122, 124],\n",
      "         [113, 140,  90,  ..., 118, 129, 152],\n",
      "         ...,\n",
      "         [ 99, 110, 111,  ..., 117, 108, 103],\n",
      "         [111, 111, 106,  ..., 106, 112, 105],\n",
      "         [111, 104, 102,  ..., 103, 110, 111]],\n",
      "\n",
      "        [[129, 123,  98,  ..., 131, 132, 145],\n",
      "         [155, 110, 137,  ..., 102, 119, 121],\n",
      "         [104, 132,  80,  ..., 112, 125, 146],\n",
      "         ...,\n",
      "         [ 93, 108, 105,  ..., 125, 115, 108],\n",
      "         [108, 108,  98,  ..., 110, 117, 110],\n",
      "         [107,  98,  95,  ..., 108, 115, 116]]], dtype=torch.uint8)\n",
      "tensor([[[202, 193, 190,  ...,  13,  13,  12],\n",
      "         [199, 192, 189,  ...,  14,  14,  14],\n",
      "         [198, 193, 188,  ...,  12,  12,  12],\n",
      "         ...,\n",
      "         [ 93,  82,  76,  ...,  36,  36,  36],\n",
      "         [ 75,  68, 101,  ...,  36,  36,  37],\n",
      "         [ 85, 103,  90,  ...,  36,  37,  38]],\n",
      "\n",
      "        [[151, 139, 133,  ...,   9,   9,   8],\n",
      "         [151, 140, 134,  ...,  11,  11,  11],\n",
      "         [152, 143, 134,  ...,  11,  11,  11],\n",
      "         ...,\n",
      "         [ 57,  45,  39,  ...,  26,  26,  26],\n",
      "         [ 33,  26,  59,  ...,  26,  26,  27],\n",
      "         [ 40,  58,  45,  ...,  26,  27,  28]],\n",
      "\n",
      "        [[ 68,  53,  44,  ...,   6,   6,   5],\n",
      "         [ 67,  54,  44,  ...,   6,   6,   6],\n",
      "         [ 67,  56,  44,  ...,   6,   6,   6],\n",
      "         ...,\n",
      "         [ 31,  19,  12,  ...,  17,  17,  17],\n",
      "         [ 11,   2,  35,  ...,  17,  17,  18],\n",
      "         [ 19,  37,  22,  ...,  17,  18,  19]]], dtype=torch.uint8)\n",
      "tensor([[[238, 238, 238,  ..., 214, 215, 215],\n",
      "         [238, 238, 238,  ..., 214, 215, 215],\n",
      "         [238, 238, 238,  ..., 214, 215, 215],\n",
      "         ...,\n",
      "         [214, 213, 212,  ..., 187, 190, 193],\n",
      "         [214, 213, 212,  ..., 186, 190, 192],\n",
      "         [214, 213, 212,  ..., 186, 190, 192]],\n",
      "\n",
      "        [[195, 195, 195,  ..., 173, 175, 175],\n",
      "         [195, 195, 195,  ..., 173, 175, 175],\n",
      "         [195, 195, 195,  ..., 173, 175, 175],\n",
      "         ...,\n",
      "         [128, 127, 126,  ..., 100, 103, 106],\n",
      "         [128, 127, 126,  ...,  99, 103, 105],\n",
      "         [128, 127, 126,  ...,  99, 103, 105]],\n",
      "\n",
      "        [[137, 137, 137,  ..., 125, 126, 126],\n",
      "         [137, 137, 137,  ..., 125, 126, 126],\n",
      "         [137, 137, 137,  ..., 125, 126, 126],\n",
      "         ...,\n",
      "         [ 79,  78,  77,  ...,  64,  68,  72],\n",
      "         [ 79,  78,  77,  ...,  64,  69,  71],\n",
      "         [ 79,  78,  77,  ...,  65,  69,  72]]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "data_dir = 'data/cats/'\n",
    "\n",
    "filenames = [name for name in os.listdir(data_dir) if os.path.splitext(name)[-1] =='.png']\n",
    "\n",
    "for i, filename in enumerate(filenames):\n",
    "    img_arr = imageio.imread(os.path.join(data_dir,filename))\n",
    "    img_t = torch.from_numpy(img_arr)\n",
    "    img_t = img_t.permute(2,0,1)\n",
    "    img_t = img_t[:3]   # only keep the first 3 channels\n",
    "    batch[i] = img_t\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a1d973f6c003acf433cab0c605c727689819527632eaa745461d95c55fb06d64"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('pytorch_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
